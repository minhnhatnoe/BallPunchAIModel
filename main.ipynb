{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import config\n",
    "\n",
    "\n",
    "def get_path(filename: str) -> tuple[str, str]:\n",
    "    return (\n",
    "        path.join(config.dataset_path, f\"{filename}_Extract.npy\"),\n",
    "        path.join(config.dataset_path, f\"{filename}.npy\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i like among us (787, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import toolset\n",
    "import numpy as np\n",
    "from npy_append_array import NpyAppendArray\n",
    "\n",
    "if os.path.exists(toolset.temp_x_path()):\n",
    "    os.remove(toolset.temp_x_path())\n",
    "if os.path.exists(toolset.temp_y_path()):\n",
    "    os.remove(toolset.temp_y_path())\n",
    "\n",
    "with NpyAppendArray(toolset.temp_x_path()) as array_x,\\\n",
    "        NpyAppendArray(toolset.temp_y_path()) as array_y:\n",
    "    for name in config.file_names:\n",
    "        paths = get_path(name)\n",
    "\n",
    "        current_x = np.load(paths[0], mmap_mode=\"r\")\n",
    "        current_x = current_x / 255.0\n",
    "        current_x = np.ascontiguousarray(current_x.transpose((0, 3, 1, 2)))\n",
    "        print(\"i like among us\", current_x.shape)\n",
    "        array_x.append(current_x)\n",
    "\n",
    "        current_y = np.load(paths[1], mmap_mode=\"r\")\n",
    "        current_y = current_y.astype(float)\n",
    "        array_y.append(current_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787, 3, 224, 224) (787,)\n"
     ]
    }
   ],
   "source": [
    "data_x = np.load(toolset.temp_x_path(), \"r\")\n",
    "data_y = np.load(toolset.temp_y_path(), \"r\")\n",
    "print(data_x.shape, data_y.shape)\n",
    "assert(data_x.shape[0] == data_y.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(config.kfold_nsplits, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nguyen Minh Nhat\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self, data: np.ndarray, label: np.ndarray) -> None:\n",
    "        self.x = data\n",
    "        self.y = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(CNNModel, self).__init__()\n",
    "        # Kernel_size: size of filter block\n",
    "        # Stride: The distance between position of the filter\n",
    "        # Padding: Non-sense at border, so that all data is preserved\n",
    "        # (in case there is remainder when dividing by kernel_size or something)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.linear1 = nn.Linear(64*56*56, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        # Go through all layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(x) \n",
    "        x = x.view(-1, 64 * 56 * 56)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(VGG16, self).__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not used!\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel()\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "    print(\"CUDA not used!\")\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_idx: np.ndarray) -> tuple[float, float]:\n",
    "    train = Data(data_x[train_idx], data_y[judge_idx])\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=config.batch_size)\n",
    "    total_loss_train = 0\n",
    "    total_accumulate_train = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x.float())\n",
    "        output = output.squeeze()\n",
    "        # print(y)\n",
    "\n",
    "        # print(type(output))\n",
    "        batch_loss = criterion(output, y)\n",
    "        \n",
    "        total_loss_train += batch_loss\n",
    "\n",
    "        accumulate = (abs(output - y) <= 0.5).sum()\n",
    "        total_accumulate_train += accumulate\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    total_loss_train = total_loss_train.item()\n",
    "    total_accumulate_train = total_accumulate_train.item()\n",
    "    return (total_loss_train, total_accumulate_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge(judge_idx: np.ndarray) -> tuple[float, float]:\n",
    "    judge = Data(data_x[judge_idx], data_y[judge_idx])\n",
    "    judge_dataloader = torch.utils.data.DataLoader(\n",
    "        judge, batch_size=config.batch_size)\n",
    "\n",
    "    total_loss_judge = 0\n",
    "    total_accumulate_judge = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(judge_dataloader):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            output = model(x.float())\n",
    "            output = output.squeeze()\n",
    "\n",
    "            batch_loss = criterion(output, y)\n",
    "            total_loss_judge += batch_loss\n",
    "\n",
    "            accumulate = (abs(output - y) <= 0.5).sum()\n",
    "            total_accumulate_judge += accumulate\n",
    "\n",
    "    total_loss_judge = total_loss_judge.item()\n",
    "    total_accumulate_judge = total_accumulate_judge.item()\n",
    "    return (total_loss_judge, total_accumulate_judge)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.15s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 \n",
      "        | Train Loss: 0.198\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.714\n",
      "        | Val Accuracy: 0.000\n",
      "Save model because val loss improve loss 3.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 2 \n",
      "        | Train Loss: 0.199\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.505\n",
      "        | Val Accuracy: 0.950\n",
      "Save model because val loss improve loss 3.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 3 \n",
      "        | Train Loss: 0.178\n",
      "        | Train Accuracy: 0.048\n",
      "        | Val Loss: 3.318\n",
      "        | Val Accuracy: 0.900\n",
      "Save model because val loss improve loss 3.318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 4 \n",
      "        | Train Loss: 0.183\n",
      "        | Train Accuracy: 0.050\n",
      "        | Val Loss: 3.404\n",
      "        | Val Accuracy: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 5 \n",
      "        | Train Loss: 0.188\n",
      "        | Train Accuracy: 0.051\n",
      "        | Val Loss: 3.504\n",
      "        | Val Accuracy: 0.950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 6 \n",
      "        | Train Loss: 0.193\n",
      "        | Train Accuracy: 0.052\n",
      "        | Val Loss: 3.598\n",
      "        | Val Accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 7 \n",
      "        | Train Loss: 0.193\n",
      "        | Train Accuracy: 0.052\n",
      "        | Val Loss: 3.597\n",
      "        | Val Accuracy: 0.850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 8 \n",
      "        | Train Loss: 0.181\n",
      "        | Train Accuracy: 0.020\n",
      "        | Val Loss: 3.485\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 9 \n",
      "        | Train Loss: 0.181\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.482\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 10 \n",
      "        | Train Loss: 0.176\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.380\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 11 \n",
      "        | Train Loss: 0.181\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.478\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 12 \n",
      "        | Train Loss: 0.187\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.573\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 13 \n",
      "        | Train Loss: 0.166\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.191\n",
      "        | Val Accuracy: 0.000\n",
      "Save model because val loss improve loss 3.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 14 \n",
      "        | Train Loss: 0.186\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.572\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 15 \n",
      "        | Train Loss: 0.182\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.479\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 16 \n",
      "        | Train Loss: 0.191\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.665\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.16s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 17 \n",
      "        | Train Loss: 0.176\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.388\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.03s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 18 \n",
      "        | Train Loss: 0.181\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.484\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 19 \n",
      "        | Train Loss: 0.176\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.384\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 20 \n",
      "        | Train Loss: 0.186\n",
      "        | Train Accuracy: 0.000\n",
      "        | Val Loss: 3.574\n",
      "        | Val Accuracy: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "min_judge_loss = float('inf')\n",
    "\n",
    "\n",
    "for epoch, (train_idx, judge_idx) in enumerate(kfold.split(data_x)):\n",
    "    total_loss_train, total_accumulate_train = train(train_idx)\n",
    "    total_loss_judge, total_accumulate_judge = judge(judge_idx)\n",
    "    print(\n",
    "        f'''Epochs: {epoch+1} \n",
    "        | Train Loss: {total_loss_train / len(train_idx):.3f}\n",
    "        | Train Accuracy: {total_accumulate_train/len(train_idx):.3f}\n",
    "        | Val Loss: {total_loss_judge/len(judge_idx):.3f}\n",
    "        | Val Accuracy: {total_accumulate_judge/len(judge_idx):.3f}'''\n",
    "    )\n",
    "    if min_judge_loss > total_loss_judge/len(judge_idx):\n",
    "        min_judge_loss = total_loss_judge/len(judge_idx)\n",
    "        torch.save(model.state_dict(), \"simplemodel.pt\")\n",
    "        print(f\"Save model because val loss improve loss {min_judge_loss:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "29ff323bbb9d9345fefb83ff23ae9b773bd1bc8480ace911be8046adb5c232f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
