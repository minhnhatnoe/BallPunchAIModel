{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import everything\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from typing import Tuple\n","from os.path import exists\n","import torch\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","from settings import cfg\n","from helper import loader\n","import export_result\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load everything"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Param size: 512.227MB\n","Buffer size: 0.032MB\n","Stats:\n","        | Number of not-punching: 34006\n","        | Number of punching: 6355\n"]}],"source":["config = cfg.TrainConfig()\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from sklearn.metrics import f1_score\n","\n","\n","def train(train_idx: np.ndarray) -> 'Tuple(float, float)':\n","    config.model.train()\n","    train_dataloader = config.get_dataloader(train_idx)\n","    total_loss_train = 0\n","\n","    prediction_array = []\n","    label_array = []\n","    for image, label in tqdm(train_dataloader):\n","        image = image.to(config.device, dtype=torch.float)\n","        image = config.transforms(image)\n","        output = config.model(image)\n","\n","        label = label.to(config.device, dtype=torch.uint8)\n","        batch_loss = config.criterion(output, label)\n","        total_loss_train += batch_loss.item()\n","\n","        prediction = output.argmax(dim=1)\n","\n","        prediction_array.append(prediction.cpu().numpy())\n","        label_array.append(label.cpu().numpy())\n","\n","        config.optimizer.zero_grad()\n","        batch_loss.backward()\n","        config.optimizer.step()\n","        config.model.zero_grad()\n","\n","    prediction_array = np.concatenate(prediction_array)\n","    label_array = np.concatenate(label_array)\n","\n","    total_accuracy_train = (prediction_array == label_array).sum().item()\n","    f1_score_train = f1_score(label_array, prediction_array, average='macro')\n","\n","    return (total_loss_train/train_idx.shape[0],\n","        total_accuracy_train/train_idx.shape[0],\n","        f1_score_train)\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def judge(judge_idx: np.ndarray) -> 'Tuple(float, float)':\n","    config.model.eval()\n","    judge_dataloader = config.get_dataloader(judge_idx)\n","    total_loss_judge = 0\n","\n","    prediction_array = []\n","    label_array = []\n","    with torch.no_grad():\n","        for image, label in tqdm(judge_dataloader):\n","            image = image.to(config.device, dtype=torch.float)\n","            output = config.model(image)\n","            label = label.to(config.device, dtype=torch.uint8)\n","\n","            batch_loss = config.criterion(output, label)\n","            total_loss_judge += batch_loss.item()\n","\n","            prediction = output.argmax(dim=1)\n","            prediction_array.append(prediction.cpu().numpy())\n","            label_array.append(label.cpu().numpy())\n","\n","    prediction_array = np.concatenate(prediction_array)\n","    label_array = np.concatenate(label_array)\n","\n","    total_accuracy_judge = (prediction_array == label_array).sum().item()\n","    f1_score_judge = f1_score(label_array, prediction_array, average='macro')\n","\n","    return (total_loss_judge/judge_idx.shape[0],\n","        total_accuracy_judge/judge_idx.shape[0],\n","        f1_score_judge)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid decimal literal (1434105874.py, line 39)","output_type":"error","traceback":["\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    | From: {min_loss_judge:.3f} | To: {avg_loss_judge:.3f}''')\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"]}],"source":["min_loss_judge = float('inf')\n","last_loss_judge = float('inf')\n","des_sequence = 0\n","under_min = 0\n","last_submit = 0\n","\n","for epoch, (train_idx, judge_idx) in enumerate(config.get_split()):\n","    print(f'''Starting epoch {epoch+1}\n","    | Train size:     {train_idx.shape[0]}   | Judge size:     {judge_idx.shape[0]}''')\n","    avg_loss_train, avg_accu_train, f1_score_train = train(train_idx)\n","    avg_loss_judge, avg_accu_judge, f1_score_judge = judge(judge_idx)\n","\n","    print(\n","        f'''Epoch: {epoch+1} \n","    | Train Loss:     {avg_loss_train:.3f}   | Judge Loss:     {avg_loss_judge:.3f}\n","    | Train Accuracy: {avg_accu_train:.3f}   | Judge Accuracy: {avg_accu_judge:.3f}\n","    | Train F1 Score: {f1_score_train:.3f}   | Judge F1 Score: {f1_score_judge:.3f}''')\n","\n","    if last_loss_judge < avg_loss_judge:\n","        des_sequence += 1\n","    if min_loss_judge < avg_loss_judge:\n","        under_min += 1\n","    else:\n","        config.save_checkpoint()\n","        print(f'''Judge loss improved:\n","    | From:           {min_loss_judge:.3f}   | To: {avg_loss_judge:.3f}''')\n","        min_loss_judge = avg_loss_judge\n","        under_min = des_sequence = 0\n","\n","    if under_min >= cfg.early_stop:\n","        print(f\"Early stop. Not better than best for {under_min} epochs.\")\n","        config.load_best()\n","        print(f\"Best model loaded.\")\n","        des_sequence = under_min = 0\n","    elif des_sequence >= cfg.des_sequence_early_stop:\n","        print(f\"Early stop. Not improved for {des_sequence} epochs.\")\n","        config.load_best()\n","        print(f\"Best model loaded.\")\n","        des_sequence = under_min = 0\n","\n","    if last_submit == 0:\n","        last_submit = f1_score_judge\n","    elif f1_score_judge - last_submit > 0.05:\n","        print(f'''Submitting:\n","    | F1 Score: {f1_score_judge:.3f} | Last Submit: {last_submit:.3f}''')\n","        last_submit = f1_score_judge\n","        export_result.submit(config)\n","    else:\n","        print(f'''Not submitting:\n","    | F1 Score: {f1_score_judge:.3f} | Last Submit: {last_submit:.3f}''')\n","    print(\"\\n____________________________________________\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 ('nhatenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"867ad48846dc57cdb6a7846b46ef358b3169581697c80695711b9dc516eb64da"}}},"nbformat":4,"nbformat_minor":2}
