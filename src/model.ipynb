{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Get the dataset"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/phuonghd/.conda/envs/nhatenv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"ename":"MemoryError","evalue":"Unable to allocate 81.9 GiB for an array with shape (10997274624,) and data type float64","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B103.143.207.68/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb#ch0000001vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B103.143.207.68/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb#ch0000001vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mconfig\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B103.143.207.68/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb#ch0000001vscode-remote?line=4'>5</a>\u001b[0m dataset_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(config\u001b[39m.\u001b[39;49mx_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B103.143.207.68/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb#ch0000001vscode-remote?line=5'>6</a>\u001b[0m dataset_label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(config\u001b[39m.\u001b[39my_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B103.143.207.68/home/phuonghd/NHAT/BallPunchAIModel/src/model.ipynb#ch0000001vscode-remote?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset_image\u001b[39m.\u001b[39mshape, dataset_label\u001b[39m.\u001b[39mshape)\n","File \u001b[0;32m~/.conda/envs/nhatenv/lib/python3.10/site-packages/numpy/lib/npyio.py:430\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode)\n\u001b[1;32m    429\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 430\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[1;32m    431\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs)\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n","File \u001b[0;32m~/.conda/envs/nhatenv/lib/python3.10/site-packages/numpy/lib/format.py:756\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    754\u001b[0m     \u001b[39mif\u001b[39;00m isfileobj(fp):\n\u001b[1;32m    755\u001b[0m         \u001b[39m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49mfromfile(fp, dtype\u001b[39m=\u001b[39;49mdtype, count\u001b[39m=\u001b[39;49mcount)\n\u001b[1;32m    757\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m         \u001b[39m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[1;32m    759\u001b[0m         \u001b[39m# memory-intensive way.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[39m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[1;32m    768\u001b[0m         \u001b[39m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[1;32m    769\u001b[0m         array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mndarray(count, dtype\u001b[39m=\u001b[39mdtype)\n","\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 81.9 GiB for an array with shape (10997274624,) and data type float64"]}],"source":["from typing import Tuple\n","import numpy as np\n","import config\n","\n","dataset_image = np.load(config.x_path, mmap_mode=\"r\")\n","dataset_label = np.load(config.y_path, mmap_mode=\"r\")\n","print(dataset_image.shape, dataset_label.shape)\n","assert(dataset_image.shape[0] == dataset_label.shape[0])\n","print(f'''Stats:\n","    | Number of not-punching: {dataset_label.sum()}\n","    | Number of punching: {dataset_label.shape[0] - dataset_label.sum()}''')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Boilerplate Code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import RepeatedKFold\n","import config\n","\n","kfold = RepeatedKFold(\n","    n_splits=config.kfold_nsplits,\n","    n_repeats=config.kfold_nrepeats,\n","    random_state=config.seed\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","class Data(torch.utils.data.Dataset):\n","    def __init__(self, image: np.ndarray, label: np.ndarray, indices: np.ndarray) -> None:\n","        assert(image.shape[0] == label.shape[0])\n","        self.image = image\n","        self.label = label\n","        self.indices = indices\n","    \n","    def __len__(self) -> int:\n","        return self.indices.shape[0]\n","    \n","    def __getitem__(self, idx: int) -> 'Tuple[np.ndarray, bool]':\n","        idx = self.indices[idx]\n","        return self.image[idx], self.label[idx]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_model(model: nn.Module):\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","    \n","    param_size  = param_size / 1024**2\n","    buffer_size = buffer_size / 1024**2\n","    print(f'Param size: {param_size:.3f}MB')\n","    print(f'Buffer size: {buffer_size:.3f}MB')\n","\n","def print_tensor(tensor: torch.Tensor):\n","    size_gb = tensor.element_size() * tensor.nelement() / (1<<30)\n","    print(f\"{size_gb:.3f}GB\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = config.get_model()\n","\n","use_cuda = torch.cuda.is_available()\n","if not use_cuda:\n","    print(\"CUDA not used!\")\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","def train(train_idx: np.ndarray) -> 'Tuple(float, float)':\n","    train = Data(dataset_image, dataset_label, train_idx)\n","    train_dataloader = torch.utils.data.DataLoader(\n","        train, batch_size=config.batch_size)\n","    total_loss_train = 0\n","    total_accumulate_train = 0\n","    for image, label in tqdm(train_dataloader):\n","        image = image.to(device, dtype=torch.float)\n","        label = label.to(device, dtype=torch.uint8)\n","        \n","        output = model(image)\n","        batch_loss = criterion(output, label)\n","\n","        total_loss_train += batch_loss\n","\n","        accumulate = (output.argmax(dim=1) == label).sum()\n","        total_accumulate_train += accumulate\n","\n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        optimizer.step()\n","\n","    total_loss_train = total_loss_train.item()\n","    total_accumulate_train = total_accumulate_train.item()\n","    return (total_loss_train, total_accumulate_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def judge(judge_idx: np.ndarray) -> 'Tuple(float, float)':\n","    judge = Data(dataset_image, dataset_label, judge_idx)\n","    judge_dataloader = torch.utils.data.DataLoader(\n","        judge, batch_size=config.batch_size)\n","\n","    total_loss_judge = 0\n","    total_accumulate_judge = 0\n","    with torch.no_grad():\n","        for image, label in tqdm(judge_dataloader):\n","            image = image.to(device, dtype=torch.float)\n","            label = label.to(device, dtype=torch.uint8)\n","\n","            output = model(image)\n","\n","            batch_loss = criterion(output, label)\n","            total_loss_judge += batch_loss\n","\n","            accumulate = (output.argmax(dim=1) == label).sum()\n","            total_accumulate_judge += accumulate\n","\n","    total_loss_judge = total_loss_judge.item()\n","    total_accumulate_judge = total_accumulate_judge.item()\n","    return total_loss_judge, total_accumulate_judge"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_judge_loss = float('inf')\n","\n","\n","for epoch, (train_idx, judge_idx) in enumerate(kfold.split(dataset_label)):\n","    print(f'''Starting epoch {epoch+1}\n","        | Train size: {train_idx.shape[0]}\n","        | Judge size: {judge_idx.shape[0]}''')\n","    total_loss_train, total_accumulate_train = train(train_idx)\n","    total_loss_judge, total_accumulate_judge = judge(judge_idx)\n","\n","    print(\n","        f'''Epoch: {epoch+1} \n","        | Train Loss: {total_loss_train / len(train_idx):.3f}\n","        | Train Accuracy: {total_accumulate_train/len(train_idx):.3f}\n","        | Val Loss: {total_loss_judge/len(judge_idx):.3f}\n","        | Val Accuracy: {total_accumulate_judge/len(judge_idx):.3f}'''\n","        \n","    )\n","    if min_judge_loss > total_loss_judge/len(judge_idx):\n","        min_judge_loss = total_loss_judge/len(judge_idx)\n","        torch.save(model.state_dict(), config.model_path)\n","        print(f\"Save model because val loss improve loss {min_judge_loss:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 ('nhatenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"867ad48846dc57cdb6a7846b46ef358b3169581697c80695711b9dc516eb64da"}}},"nbformat":4,"nbformat_minor":2}
