{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Get the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import config\n","\n","dataset_image = np.load(config.x_path)\n","dataset_label = np.load(config.y_path)\n","print(dataset_image.shape, dataset_label.shape)\n","assert(dataset_image.shape[0] == dataset_label.shape[0])\n"]},{"cell_type":"markdown","metadata":{},"source":["# Boilerplate Code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import KFold\n","import config\n","\n","kfold = KFold(config.kfold_nsplits, shuffle=True, random_state=config.seed)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Tuple\n","import torch\n","\n","class Data(torch.utils.data.Dataset):\n","    def __init__(self, image: np.ndarray, label: np.ndarray) -> None:\n","        assert(image.shape[0] == label.shape[0])\n","        self.image = image\n","        self.label = label\n","    \n","    def __len__(self):\n","        return self.image.shape[0]\n","    \n","    def __getitem__(self, idx: int):\n","        return self.image[idx], self.label[idx]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn\n","from torchvision.models import vgg16, VGG16_Weights\n","\n","\n","def get_model() -> nn.Module:\n","    model = vgg16(weights=VGG16_Weights.DEFAULT, progress=True)\n","    in_features = model.classifier[6].in_features\n","    model.classifier[6] = nn.Linear(in_features, 2)\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = get_model()\n","\n","use_cuda = torch.cuda.is_available()\n","if not use_cuda:\n","    print(\"CUDA not used!\")\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","model = model.to(device)\n","criterion = criterion.to(device)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","def train(train_idx: np.ndarray) -> 'Tuple(float, float)':\n","    print(\"TRAINING\")\n","    train = Data(dataset_image[train_idx], dataset_label[train_idx])\n","    train_dataloader = torch.utils.data.DataLoader(\n","        train, batch_size=config.batch_size)\n","    print(\"MADE DATALOADER\")\n","    total_loss_train = 0\n","    total_accumulate_train = 0\n","    for image, label in tqdm(train_dataloader):\n","        image = image.to(device, dtype=torch.float)\n","        label = label.to(device, dtype=torch.uint8)\n","        output = model(image)\n","        print(\"OUT: \", output)\n","        print(\"LABEL: \", label)\n","\n","        batch_loss = criterion(output, label)\n","\n","        total_loss_train += batch_loss\n","\n","        accumulate = (output.argmax(dim=1) == label).sum()\n","        total_accumulate_train += accumulate\n","\n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        optimizer.step()\n","\n","    total_loss_train = total_loss_train.item()\n","    total_accumulate_train = total_accumulate_train.item()\n","    return (total_loss_train, total_accumulate_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def judge(judge_idx: np.ndarray) -> 'Tuple(float, float)':\n","    judge = Data(dataset_image[judge_idx], dataset_label[judge_idx])\n","    judge_dataloader = torch.utils.data.DataLoader(\n","        judge, batch_size=config.batch_size)\n","\n","    total_loss_judge = 0\n","    total_accumulate_judge = 0\n","    with torch.no_grad():\n","        for image, label in tqdm(judge_dataloader):\n","            image = image.to(device, dtype=torch.float)\n","            label = label.to(device, dtype=torch.uint8)\n","\n","            output = model(image)\n","\n","            batch_loss = criterion(output, label)\n","            total_loss_judge += batch_loss\n","\n","            accumulate = (output.argmax(dim=1) == label).sum()\n","            total_accumulate_judge += accumulate\n","\n","    total_loss_judge = total_loss_judge.item()\n","    total_accumulate_judge = total_accumulate_judge.item()\n","    return total_loss_judge, total_accumulate_judge"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","min_judge_loss = float('inf')\n","\n","\n","for epoch, (train_idx, judge_idx) in enumerate(kfold.split(dataset_label)):\n","    print(epoch)\n","    total_loss_train, total_accumulate_train = train(train_idx)\n","    total_loss_judge, total_accumulate_judge = judge(judge_idx)\n","\n","    print(\n","        f'''Epochs: {epoch+1} \n","        | Train Loss: {total_loss_train / len(train_idx):.3f}\n","        | Train Accuracy: {total_accumulate_train/len(train_idx):.3f}\n","        | Val Loss: {total_loss_judge/len(judge_idx):.3f}\n","        | Val Accuracy: {total_accumulate_judge/len(judge_idx):.3f}'''\n","        \n","    )\n","    if min_judge_loss > total_loss_judge/len(judge_idx):\n","        min_judge_loss = total_loss_judge/len(judge_idx)\n","        torch.save(model.state_dict(), \"simplemodel.pt\")\n","        print(f\"Save model because val loss improve loss {min_judge_loss:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"}}},"nbformat":4,"nbformat_minor":2}
