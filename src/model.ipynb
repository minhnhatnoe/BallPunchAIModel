{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Get the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Tuple\n","import numpy as np\n","import config\n","\n","dataset_image = np.load(config.x_path, mmap_mode='c')\n","dataset_label = np.load(config.y_path, mmap_mode='c')\n","assert(dataset_image.shape[0] == dataset_label.shape[0])\n","print(f'''Stats:\n","    | Number of punching: {dataset_label.sum()}\n","    | Number of not-punching: {dataset_label.shape[0] - dataset_label.sum()}''')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Boilerplate Code"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import RepeatedKFold\n","import config\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","class Data(torch.utils.data.Dataset):\n","    def __init__(self, image: np.ndarray, label: np.ndarray, indices: np.ndarray) -> None:\n","        assert(image.shape[0] == label.shape[0])\n","        self.image = image\n","        self.label = label\n","        self.indices = indices\n","    \n","    def __len__(self) -> int:\n","        return self.indices.shape[0]\n","    \n","    def __getitem__(self, idx: int) -> 'Tuple[np.ndarray, bool]':\n","        idx = self.indices[idx]\n","        return self.image[idx], self.label[idx]\n"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from torch import nn\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def print_model(model: nn.Module):\n","    param_size = 0\n","    for param in model.parameters():\n","        param_size += param.nelement() * param.element_size()\n","    buffer_size = 0\n","    for buffer in model.buffers():\n","        buffer_size += buffer.nelement() * buffer.element_size()\n","    \n","    param_size  = param_size / 1024**2\n","    buffer_size = buffer_size / 1024**2\n","    print(f'Param size: {param_size:.3f}MB')\n","    print(f'Buffer size: {buffer_size:.3f}MB')\n","\n","def print_tensor(tensor: torch.Tensor):\n","    size_gb = tensor.element_size() * tensor.nelement() / (1<<30)\n","    print(f\"{size_gb:.3f}GB\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = config.get_model()\n","\n","optimizer = \n","\n","model = model.to(config.device)\n","criterion = criterion.to(config.device)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tqdm import tqdm\n","def train(train_idx: np.ndarray) -> 'Tuple(float, float)':\n","    train = Data(dataset_image, dataset_label, train_idx)\n","    train_dataloader = torch.utils.data.DataLoader(\n","        train, batch_size=config.batch_size)\n","    total_loss_train = 0\n","    total_accumulate_train = 0\n","    model.train()\n","    for image, label in tqdm(train_dataloader):\n","        image = image.to(config.device, dtype=torch.float)\n","        label = label.to(config.device, dtype=torch.uint8)\n","        image = config.random_transforms(image)\n","        output = model(image)\n","\n","        batch_loss = criterion(output, label)\n","\n","        total_loss_train += batch_loss.item()\n","\n","        accumulate = (output.argmax(dim=1) == label).sum()\n","        total_accumulate_train += accumulate.item()\n","\n","        optimizer.zero_grad()\n","        batch_loss.backward()\n","        optimizer.step()\n","        model.zero_grad()\n","\n","    return (total_loss_train, total_accumulate_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def judge(judge_idx: np.ndarray) -> 'Tuple(float, float)':\n","    judge = Data(dataset_image, dataset_label, judge_idx)\n","    judge_dataloader = torch.utils.data.DataLoader(\n","        judge, batch_size=config.batch_size)\n","\n","    total_loss_judge = 0\n","    total_accumulate_judge = 0\n","    with torch.no_grad():\n","        for image, label in tqdm(judge_dataloader):\n","            image = image.to(config.device, dtype=torch.float)\n","            label = label.to(config.device, dtype=torch.uint8)\n","\n","            output = model(image)\n","            batch_loss = criterion(output, label)\n","            total_loss_judge += batch_loss.item()\n","\n","            accumulate = (output.argmax(dim=1) == label).sum()\n","            total_accumulate_judge += accumulate.item()\n","\n","    return total_loss_judge, total_accumulate_judge"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["min_judge_loss = float('inf')\n","\n","\n","for epoch, (train_idx, judge_idx) in enumerate(kfold.split(dataset_label)):\n","    print(f'''Starting epoch {epoch+1}\n","        | Train size: {train_idx.shape[0]}\n","        | Judge size: {judge_idx.shape[0]}''')\n","    total_loss_train, total_accumulate_train = train(train_idx)\n","    total_loss_judge, total_accumulate_judge = judge(judge_idx)\n","\n","    print(\n","        f'''Epoch: {epoch+1} \n","        | Train Loss: {total_loss_train / len(train_idx):.3f}\n","        | Train Accuracy: {total_accumulate_train/len(train_idx):.3f}\n","        | Val Loss: {total_loss_judge/len(judge_idx):.3f}\n","        | Val Accuracy: {total_accumulate_judge/len(judge_idx):.3f}'''\n","    )\n","    if min_judge_loss > total_loss_judge/len(judge_idx):\n","        min_judge_loss = total_loss_judge/len(judge_idx)\n","        torch.save(model.state_dict(), config.model_path)\n","        print(f\"Save model because val loss improve loss {min_judge_loss:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 ('nhatenv')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"867ad48846dc57cdb6a7846b46ef358b3169581697c80695711b9dc516eb64da"}}},"nbformat":4,"nbformat_minor":2}
